[
  {
    "objectID": "ocm.html",
    "href": "ocm.html",
    "title": "ocm",
    "section": "",
    "text": "An ARC task can be described using an input grid model and an output grid model.",
    "crumbs": [
      "ocm"
    ]
  },
  {
    "objectID": "ocm.html#properties",
    "href": "ocm.html#properties",
    "title": "ocm",
    "section": "Properties",
    "text": "Properties\nFirst we will define a few classes for declaring properties of grids and their objects\n\nsource\n\nVector\n\n Vector (i:int, j:int)\n\n2D vector for positions, sizes, and directions.\nWe will use a Vector class for specifying positions etc. in ARC grids. Positions are denoted as an (i, j) coordinate with respect to the top-left corner of an ARC grid.\n\nVector(0,0)\n\nVector(i=0, j=0)\n\n\nAddition, subtraction and scalar multiplication are supported\n\ntest_eq(Vector(2,2), Vector(1,1) + Vector(1,1))\ntest_eq(Vector(6,2), 2*Vector(3,1))\ntest_ne(Vector(2,3), Vector(3,2))\n\nThe to_array method returns a numpy array\n\nVector(i=3, j=7).to_array()\n\narray([3, 7])\n\n\nThere is also a from_array class method, though unpacking is more concise\n\ntest_eq(\n    Vector.from_array(np.array([1,2])), \n    Vector(*np.array([1,2]))\n)\n\n\nsource\n\n\nColor\n\n Color (value:Union[int,str])\n\nRepresents a color using an integer value (0-9) or a color name.\nThere are 10 colors in ARC grids:\n\nprint(Color.colors)\n\n['black', 'blue', 'red', 'green', 'yellow', 'grey', 'pink', 'orange', 'cyan', 'brown']\n\n\nThe Color class holds the mapping, allowing us to instantiate color properties using either the name or integer value\n\nColor('blue')\n\nColor('blue', value=1)\n\n\n\ntest_eq(Color('green'), Color(3))\n\n\nsource\n\n\nDirection\n\n Direction (value, names=None, module=None, qualname=None, type=None,\n            start=1)\n\nRepresents cardinal and intercardinal directions as 2D vectors.\nWith Direction, we can describe objects such as a line by their start position, length and direction.\n\nDirection.UP.value\n\nVector(i=-1, j=0)",
    "crumbs": [
      "ocm"
    ]
  },
  {
    "objectID": "ocm.html#objects",
    "href": "ocm.html#objects",
    "title": "ocm",
    "section": "Objects",
    "text": "Objects\nThe core primitive in ARC tasks is the concept of an Object, located at a position somewhere in the grid. We will define specific classes for different shapes that will each inherit from this base clase.\n\nsource\n\nObject\n\n Object (position:__main__.Vector)\n\nBase class for shape objects in ARC tasks.\n\nsource\n\n\nRectangle\n\n Rectangle (position:__main__.Vector, size:__main__.Vector,\n            color:__main__.Color)\n\nRectangular shape.\nThe simplest object is a Rectangle, which represents any contiguous rectangular sub-array within the grid. A singleton cell is just a Rectangle of size Vector(1,1)\nWe give each specific shape a _get_shape_array private method for converting it into a numpy array, e.g.:\n\nrec = Rectangle(position=Vector(0,0), size=Vector(3,3), color=Color('red'))\nrec._get_shape_array()\n\narray([[2, 2, 2],\n       [2, 2, 2],\n       [2, 2, 2]])\n\n\n\nsource\n\n\nLine\n\n Line (position:__main__.Vector, direction:__main__.Direction,\n       length:typing.Annotated[int,Gt(gt=0)], color:__main__.Color)\n\nLine shape.\nARC grids often feature straight line objects; e.g.¬†spanning the grid, connecting more complex shapes, etc. To allow us to capture both horizontal/vertical and diagonal lines, we‚Äôll create a new primitive.\nFor diagonal lines, the _get_shape_array method will return a 2d array with the color value along the appropriate diagonal and -1 elsewhere\n\nl = Line(position=Vector(5,5), direction=Direction.NW, length=4, color=Color(3))\nl._get_shape_array()\n\narray([[ 3, -1, -1, -1],\n       [-1,  3, -1, -1],\n       [-1, -1,  3, -1],\n       [-1, -1, -1,  3]])\n\n\nNote that the position of an object in the grid always refers to its top-left corner. For an orthogonal line with direction UP or LEFT, or for diagonal lines with direction NW, NE or SW, we will need to subtract an offset to determine the object‚Äôs correct position.\n\nl.offset\n\nVector(i=-3, j=-3)\n\n\n\nsource\n\n\nBitmap\n\n Bitmap (position:__main__.Vector, data:numpy.ndarray)\n\nMulti-colored bitmap pattern.\nThe Bitmap object represents more complex shapes and patterns, including multi-colored patterns.\n\nb = Bitmap(position=Vector(2,3), data=np.array([[3,0],[3,3],[0,3]])); b\n\nBitmap(position=Vector(i=2, j=3), data=array([[3, 0],\n       [3, 3],\n       [0, 3]]))\n\n\nWe can now define a general to_array method for all objects\n\nsource\n\n\nObject.to_array\n\n Object.to_array (grid_size:Optional[__main__.Vector]=None)\n\nIf grid_size is provided, returns the object positioned within a grid of that size. If grid_size is None, returns just the object‚Äôs array.\nLet‚Äôs check the Line object we created. For now, we‚Äôll just use matplotlib‚Äôs imshow to visualise the array\nIt‚Äôs a line of length 4, starting at (5,5) and extending in a NW direction.\n\nl\n\nLine(position=Vector(i=5, j=5), direction=&lt;Direction.NW: Vector(i=-1, j=-1)&gt;, length=4, color=Color('green', value=3))\n\n\nWhen we use the grid_size argument, it will place the object in the correct position within a larger array\n\nplt.imshow(\n    l.to_array(grid_size=Vector(7,7))\n);",
    "crumbs": [
      "ocm"
    ]
  },
  {
    "objectID": "ocm.html#grid",
    "href": "ocm.html#grid",
    "title": "ocm",
    "section": "Grid",
    "text": "Grid\nThe final primitive is a container for multiple objects representing a grid.\n\nsource\n\nGrid\n\n Grid (size:__main__.Vector,\n       background_color:Optional[__main__.Color]=None,\n       objects:List[__main__.Object]=&lt;factory&gt;)\n\nGrid container with a size, background color, and objects.\nNow we have everything we need to define grid models.",
    "crumbs": [
      "ocm"
    ]
  },
  {
    "objectID": "ocm.html#example",
    "href": "ocm.html#example",
    "title": "ocm",
    "section": "Example",
    "text": "Example\nLet‚Äôs define grid models for an ARC task\n\nt = random.choice(train_tasks)\ntask = ArcTask(t); task\n\nArcTask(id='d037b0a7', train_examples=3, test_examples=1)\n\n\n\ntask.plot()\n\n\n\n\n\n\n\n\n\ntask.test[0].input.plot()\n\n\n\n\n\n\n\n\nThe input grids are all 3x3 and have a black background, containing at least one singleton colored cell. It‚Äôs simple to define a model for valid grids in this task:\n\nclass InputModel(Grid):\n    size: Literal[Vector(3, 3)]\n    background_color: Literal[Color(0)] = Color(0)\n\n    @classmethod\n    def from_array(cls, arr: np.ndarray) -&gt; 'InputModel':\n        # Find non-black cells\n        non_black_positions = np.argwhere(arr != Color(0).value)\n        \n        return cls(\n            size=Vector(*arr.shape),\n            objects=[\n                Rectangle(position=Vector(i=row, j=col),\n                          size=Vector(1,1),\n                          color=Color(c))\n                for row, col in non_black_positions\n                for c in [arr[row, col]]\n            ]\n        )\n\nThe from_array class method parses an arbitrary numpy array and creates an instance of this Grid class (assuming that the array is a valid example of a grid from this task).\nWe can test that the input model is correctly parsing the grid by testing if its to_array method reconstructs the original array.\n\nin_grid = InputModel.from_array(task.train[0].input.data)\nArcGrid(data=in_grid.to_array()).plot()\n\n\n\n\n\n\n\n\n\nfor example in task.train:\n    in_arr = example.input.data\n    test_eq(in_arr, InputModel.from_array(in_arr).to_array())\n\nAn output model for this task just needs to construct vertical lines starting at each colored cell and extending down to the bottom of the grid.\n\nclass OutputModel(Grid):\n    @classmethod\n    def from_input(cls, input_grid: InputModel) -&gt; 'OutputModel':\n        size = input_grid.size\n        # construct vertical lines extending downward from each colored point\n        objects = [\n            Line(position=o.position, direction=Direction.DOWN, length=3-o.position.i, color=o.color)\n            for o in input_grid.objects\n        ]\n\n        return cls(\n            size=size,\n            background_color=input_grid.background_color,\n            objects=objects\n        )\n\n\nout_grid = OutputModel.from_input(in_grid)\nArcGrid(out_grid.to_array()).plot()\n\n\n\n\n\n\n\n\nLet‚Äôs test it out on the test example\n\nin_grid_test = InputModel.from_array(\n    task.test[0].input.data\n)\nout_grid_test = OutputModel.from_input(in_grid_test)\n\n\nArcPair(\n    input_grid=in_grid_test.to_array(),\n    output_grid=out_grid_test.to_array()\n).plot()\n\n\n\n\n\n\n\n\nLooks good! Let‚Äôs double check against the hidden test array\n\nArcGrid(task.test[0].output.data) == ArcGrid(out_grid_test.to_array())\n\nTrue",
    "crumbs": [
      "ocm"
    ]
  },
  {
    "objectID": "ocm.html#helper-functions",
    "href": "ocm.html#helper-functions",
    "title": "ocm",
    "section": "Helper Functions",
    "text": "Helper Functions\nWe can define a few helper functions for perfoming common operations in ARC tasks\n\nsource\n\nShapeExtractor\n\n ShapeExtractor ()\n\nExtract distinct ‚Äúshapes‚Äù (i.e.¬†contiguous regions of the same value) from a numpy array\nDuring parsing, almost all ARC tasks involve extracting specific shapes. This helper functions removes the need to implement this logic each time. It contains various static methods, e.g.:\n\nsource\n\n\nShapeExtractor.extract_all_shapes\n\n ShapeExtractor.extract_all_shapes (array:numpy.ndarray,\n                                    include_diagonal:bool=False,\n                                    background_color:Optional[int]=None)\n\nExtract all shapes of all values from a numpy array.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\narray\nndarray\n\nNumpy array\n\n\ninclude_diagonal\nbool\nFalse\nConsider diagonally adjacent cells as connected or not\n\n\nbackground_color\nOptional\nNone\nOptionally specify a background color to ignore\n\n\nReturns\nList\n\nList of (sub-array, position, color_value) tuples\n\n\n\n\nsource\n\n\nPatternMatcher\n\n PatternMatcher ()\n\nA class for finding alignments between patterns in numpy arrays. Supports exact matching and partial matching with missing or extra elements.\nOften we have extracted a shape (as a subarray) from a grid and we need to find the positions of other identical shapes within a grid. Another common situation is that we have a partial shape and we need to align it with a full version of the shape in a grid. This class allows us to do that, sliding over the larger array and returning the position that maximises agreement between the subarray and the area of the larger array, e.g.:\n\nsource\n\n\nPatternMatcher.find_best_match\n\n PatternMatcher.find_best_match (target:numpy.ndarray,\n                                 pattern:numpy.ndarray,\n                                 match_type:str='exact')\n\nFind the best matching position for the pattern in the target.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget\nndarray\n\ntarget array\n\n\npattern\nndarray\n\nthe pattern to align\n\n\nmatch_type\nstr\nexact\ncan be ‚Äòexact‚Äô, ‚Äòallow_missing‚Äô or ‚Äòallow_extra‚Äô\n\n\nReturns\nTuple\n\ntuple of (position, overlap_count)\n\n\n\n\nsource\n\n\nEnclosureFiller\n\n EnclosureFiller ()\n\nFill areas of an array that are ‚Äúenclosed‚Äù by cells of a given value\n\nsource\n\n\nCyclicPattern\n\n CyclicPattern (data:numpy.ndarray, period:int,\n                axis:typing.Annotated[int,Ge(ge=0),Le(le=1)]=0)\n\nIdentify, represent, and manipulate cyclic patterns in ARC task grids, particularly for tasks involving pattern repetition and extension.",
    "crumbs": [
      "ocm"
    ]
  },
  {
    "objectID": "score.html",
    "href": "score.html",
    "title": "score",
    "section": "",
    "text": "We need a way of evaluating predicted ARC grids against the true output grids.\nA simple approach is to calculate the proportion of correct cells.\n\ndef score(\n    truth: ArcGrid,  # True ARC grid\n    pred: ArcGrid    # Predicted ARC grid\n) -&gt; float:\n    \"Score a predicted grid against the true grid\"\n    if pred == truth: return 1.0\n\n    return float(np.mean(pred.data == truth.data))\n\n\npair = ArcPair(input_grid = np.array([[1,2,3],[4,5,6]]),\n               output_grid = np.array([[3,2,1],[4,5,6]]))\n\n\npair.plot(titles=['Truth', 'Prediction'])\n\n\n\n\n\n\n\n\n\nscore(*pair)\n\n0.6666666666666666\n\n\nOften the predicted grid has the wrong shape. We could simply return 0.0. Instead, let‚Äôs pad the grids to be equal shape and assign partial credit to correctly predicted cells in the overlapping region\n\nsource\n\nscore\n\n score (truth:arcsolver.task.ArcGrid, pred:arcsolver.task.ArcGrid|None)\n\nScore a predicted grid against the true grid\n\n\n\n\nType\nDetails\n\n\n\n\ntruth\nArcGrid\nTrue ARC grid\n\n\npred\narcsolver.task.ArcGrid | None\nPredicted ARC grid\n\n\nReturns\nfloat\n\n\n\n\n\n\nExported source\ndef score(\n    truth: ArcGrid,         # True ARC grid\n    pred: ArcGrid | None    # Predicted ARC grid\n) -&gt; float:\n    \"Score a predicted grid against the true grid\"\n    if pred is None: return 0.0\n    if pred == truth: return 1.0\n    \n    # Calculate shape penalty\n    rows_ratio = min(truth.shape[0], pred.shape[0]) / max(truth.shape[0], pred.shape[0])\n    cols_ratio = min(truth.shape[1], pred.shape[1]) / max(truth.shape[1], pred.shape[1])\n    shape_penalty = rows_ratio * cols_ratio\n\n    # Get overlapping region dimensions\n    overlap_rows = min(truth.shape[0], pred.shape[0])\n    overlap_cols = min(truth.shape[1], pred.shape[1])\n\n    # Calculate color accuracy in overlapping region\n    true_overlap = truth.data[:overlap_rows, :overlap_cols]\n    pred_overlap = pred.data[:overlap_rows, :overlap_cols]\n    color_accuracy = np.mean(true_overlap == pred_overlap)\n\n    return float(shape_penalty * color_accuracy)\n\n\n\nscore(*pair)\n\n0.6666666666666666\n\n\n\npair = ArcPair(input_grid = np.array([[1,2,3],[4,5,6]]),\n               output_grid = np.array([[3,2,1],[4,5,6], [7,8,9]]))\npair.plot(titles=['Truth', 'Prediction'])\n\n\n\n\n\n\n\n\n\nscore(*pair)\n\n0.4444444444444444\n\n\n\npair = ArcPair(input_grid = np.array([[1,2,3],[4,5,6],[7,8,9]]),\n               output_grid = np.array([[3,2,1],[4,5,6]]))\npair.plot(titles=['Truth', 'Prediction'])\n\n\n\n\n\n\n\n\n\nscore(*pair)\n\n0.4444444444444444",
    "crumbs": [
      "score"
    ]
  },
  {
    "objectID": "solve.html",
    "href": "solve.html",
    "title": "solve",
    "section": "",
    "text": "This module implements a solver agent that generates, validates and tests candidate solutions to a given task, then iteratively attempts to refine its solutions based on execution and prediction error feedback. The solver carries out the following process:\n\nAnalyse the task and generate n descriptions concurrently (using the direct or indirect method or a combination)\nBased on these, generate n candidate solutions concurrently using the OCM framework\n\nDuring generation, solutions are automatically parsed and validated for syntax errors\n\nIn isolated python subprocesses, run all solutions against the task data in parallel, constructing output grid predictions\nCalculate scores for all solutions based on cell-wise accuracy\nIf any solutions correctly predict all train examples:\n\nValidate against the test example and return if successful\n\nElse:\n\nConstruct a feedback prompt for Claude, including any execution errors and an image of the true vs predicted grids\n\nRepeat up to a max number of attempts\n\n\nsource\n\nSolution\n\n Solution (reasoning:str, new_primitives:str, input_model:str,\n           output_model:str)\n\nCode components of a single ARC solution attempt.\nWe use a system prompt that instructs Claude to respond with chain of thought reasoning, followed by its solution code, formatted using xml tags:  for proposed new OCM primitives for solving this and other ARC tasks,  for the input grid model and  for the output grid model. The Solution dataclass automatically parses the xml response and stores the various components.\nThis class will throw an exception if the xml parsing fails. We can also parse the generated code to check for syntax errors.\nBefore running the code, we can use ast to validate that it contains the correct model names, class methods etc. and doesn‚Äôt raise syntax errors.\n\nsource\n\n\nCodeValidator\n\n CodeValidator ()\n\nValidates that ARC solution code has required classes and methods\nLet‚Äôs test it out. To encourage the correct code format, we‚Äôll insert a few examples into the chat history.\n\nchat = _create_chat(model, _create_client('bedrock', {}), sp=sp_solve)\nfor e in examples:\n    chat.h.append(e.description)\n    chat.h.append((f\"&lt;reasoning&gt;\\n{e.reasoning}\\n&lt;/reasoning&gt;\\n\\n&lt;new_primitives&gt;\\n{e.new_primitives}\\n\"\n                   f\"&lt;/new_primitives&gt;\\n\\n&lt;input_model&gt;\\n{e.input_model}\\n&lt;/input_model&gt;\\n\\n\"\n                   f\"&lt;output_model&gt;\\n{e.output_model}\\n&lt;/output_model&gt;\"))\n\nr = await chat(\n    ds[0].d,\n    prefill=\"&lt;reasoning&gt;\", temp=0.6, stop='&lt;/output_model&gt;'\n)\nif r.stop_reason == 'stop_sequence': r.content[0].text += '&lt;/output_model&gt;'\n\n\nsol = Solution.from_response(r.content[0].text)\nCodeValidator.validate(sol.full_code)\nprint(sol.input_model)\n\nclass InputModel(Grid):\n    \"\"\"\n    Model for input grid containing scattered colored pixels.\n    \"\"\"\n    pixel_positions: Dict[int, List[Vector]] = Field(default_factory=dict)\n    \n    @classmethod\n    def from_array(cls, arr: np.ndarray) -&gt; 'InputModel':\n        positions = {}\n        objects = []\n        \n        # Extract positions of each colored pixel\n        for i in range(arr.shape[0]):\n            for j in range(arr.shape[1]):\n                if arr[i,j] &gt; 0:\n                    color = arr[i,j]\n                    if color not in positions:\n                        positions[color] = []\n                    pos = Vector(i=i, j=j)\n                    positions[color].append(pos)\n                    objects.append(Rectangle(\n                        position=pos,\n                        size=Vector(i=1, j=1),\n                        color=Color(color)\n                    ))\n        \n        return cls(\n            size=Vector(*arr.shape),\n            background_color=Color(0),\n            pixel_positions=positions,\n            objects=objects\n        )\n\n\nIn fact, we can run this parsing and validating automatically and trigger retries if either fails. Let‚Äôs patch a new chat method for this\n\nsource\n\n\nAsyncChat.codeloop\n\n AsyncChat.codeloop (pr:str, max_attempts:int=3,\n                     prefill:str='&lt;reasoning&gt;',\n                     stop:str='&lt;/output_model&gt;',\n                     trace_func:Optional[&lt;built-infunctioncallable&gt;]=None,\n                     temp=0, maxtok=4096, stream=False)\n\nGenerate and validate solution code from Claude, automatically retrying on validation errors\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npr\nstr\n\nInitial prompt to pass to Claude\n\n\nmax_attempts\nint\n3\nMaximum number of retry attempts\n\n\nprefill\nstr\n\nText to prefill assistant‚Äôs response with\n\n\nstop\nstr\n\nStop sequence for generation\n\n\ntrace_func\nOptional\nNone\nFunction to trace attempts (e.g.¬†print)\n\n\ntemp\nint\n0\nTemperature\n\n\nmaxtok\nint\n4096\nMaximum tokens\n\n\nstream\nbool\nFalse\nStream response?\n\n\nReturns\nSolution\n\nValidated solution attempt from Claude‚Äôs response\n\n\n\n\nsource\n\n\nAttempt\n\n Attempt (task:arcsolver.task.ArcTask,\n          description:arcsolver.describe.Description, depth:int,\n          solution:Optional[__main__.Solution]=None,\n          chat:Optional[claudette.asink.AsyncChat]=None,\n          parent:Optional[ForwardRef('Attempt')]=None,\n          children:List[ForwardRef('Attempt')]=&lt;factory&gt;,\n          result:Optional[__main__.ExecutionResult]=None,\n          error:Optional[str]=None)\n\nAn attempt at solving an ARC task.\nThe Attempt class stores everything relating to a single attempt. The solver will create a tree structure of attempts, with the root node being a description. Each subsequent attempt has a parent and a list of children, where a child is formed when we retry an attempt using execution/prediction error feedback.\nNext, we need to run the generated code and make predictions on the training examples. Let‚Äôs define a container for a code execution result\n\nsource\n\n\nExecutionResult\n\n ExecutionResult (in_preds:Optional[List[arcsolver.task.ArcGrid]]=None,\n                  out_preds:Optional[List[arcsolver.task.ArcGrid]]=None,\n                  error:Optional[str]=None,\n                  example_errors:Optional[List[str]]=None)\n\nContains all results from a solution attempt execution\nTo generate an ExecutionResult, we‚Äôll run an Attempt‚Äôs code in a separate python process.\n\nsource\n\n\nSandboxedExecutor\n\n SandboxedExecutor ()\n\nExecutes ARC solutions in a separate Python process with detailed results\n\n\n\n\n\n\nWarning\n\n\n\nNote that we are executing code generated by AI models. While designed for research and experimentation, it includes basic safety measures:\n\nCode is pre-validated to check for specifically requested class names and methods.\nCode execution occurs in isolated subprocesses\nEach execution has a 5-second timeout limit\nExceptions are caught and handled safely\n\nUsers should exercise appropriate caution and avoid running unknown solutions in security-critical environments.\n\n\nWe can use ProcessPoolExecutor to run all attempts in parallel\n\nsource\n\n\nConcurrentExecutor\n\n ConcurrentExecutor (max_workers:Optional[int]=None)\n\nExecutes multiple ARC solution attempts concurrently\nIf an attempt is unsuccessful, we can write a function to generate a prompt for Claude to try again. We‚Äôll parse a result and feed back which predictions were correct, if any and what error messages were encountered, if any.\n\nsource\n\n\nfeedback\n\n feedback (attempt:__main__.Attempt)\n\nGenerate feedback message for Claude based on execution results\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nattempt\nAttempt\nIncorrect attempt\n\n\nReturns\nlist\nfeedback prompt for claudette, maybe including an image of an incorrect prediction\n\n\n\n\nfb = feedback(attempts[0])\nprint(fb[0] if len(fb) == 1 else fb[-1])\n\nWell done, your input grid model was able to correctly reconstruct all input arrays.\n\nUnfortunately, your output model made incorrect predictions for examples 1, 2, 3.\n\nAttached is an image of the true output grid (left) and your model's prediction (right) for example 3.\n\nPlease try again, responding in the same style as before. Use &lt;reasoning&gt; tags to explain your thought process for addressing these issues, then proceed with &lt;new_primitives&gt;, &lt;input_model&gt; and &lt;output_model&gt;.\nIMPORTANT: Remember the core principles! Do not implement example-specific logic or rules based on this image.\n\n\n\nsource\n\n\nArcSolver\n\n ArcSolver (model:str='claude-3-5-sonnet-20241022',\n            client_type:str='anthropic',\n            client_kwargs:Optional[Dict]=None, describer:Optional[arcsolve\n            r.describe.DescriptionGenerator]=None,\n            solve_sp:Optional[str]=None, max_workers:Optional[int]=None,\n            top_n:int=2, logger:Optional[logging.Logger]=None)\n\n(Attempt to) Solve an ARC task using Claude.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel\nstr\nclaude-3-5-sonnet-20241022\nModel identifier (defaults to Sonnet 3.5)\n\n\nclient_type\nstr\nanthropic\n‚Äòanthropic‚Äô, ‚Äòbedrock‚Äô, or ‚Äòvertex‚Äô\n\n\nclient_kwargs\nOptional\nNone\nOptional kwargs for client instantiation\n\n\ndescriber\nOptional\nNone\nOptional custom description generator\n\n\nsolve_sp\nOptional\nNone\nCustom system prompt for solution generation\n\n\nmax_workers\nOptional\nNone\nMax concurrent processes for execution\n\n\ntop_n\nint\n2\nNumber of best attempts to retry from\n\n\nlogger\nOptional\nNone\nOptional pre-configured logger\n\n\n\n\nsource\n\n\nArcSolver.solve\n\n ArcSolver.solve (task:arcsolver.task.ArcTask|str, d_direct:int=1,\n                  d_indirect:int=1, budget:int=30, temp:float=0.7,\n                  **kwargs)\n\nGenerate and iteratively refine solutions until success or budget exhausted.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntask\narcsolver.task.ArcTask | str\n\nARC task or task ID to solve\n\n\nd_direct\nint\n1\nNumber of direct descriptions to generate\n\n\nd_indirect\nint\n1\nNumber of indirect descriptions to generate\n\n\nbudget\nint\n30\nMaximum number of solution attempts\n\n\ntemp\nfloat\n0.7\nTemperature for generation\n\n\nkwargs\n\n\n\n\n\nReturns\nList\n\nSuccessful solutions found, if any\n\n\n\nLet‚Äôs try it out on an example task\n\nt = random.choice(train_tasks)\ntask = ArcTask(t)\nprint(f\"Task: {t}\\n\")\ntask.plot()\n\nTask: ae3edfdc\n\n\n\n\n\n\n\n\n\n\n\nsolver = ArcSolver(model, 'bedrock', top_n=5)\nsolutions = await solver.solve(task, d_direct=14, d_indirect=1, budget=50)\n\n\nSolving task: ae3edfdc\nGenerating descriptions... | Attempts: 0/50 | Best Score: 0.000 | Cost: $0.000\nStarting solution attempts... | Attempts: 0/50 | Best Score: 0.000 | Cost: $0.374\nGenerating initial solutions... | Attempts: 0/50 | Best Score: 0.000 | Cost: $0.374\nTesting solutions... | Attempts: 0/50 | Best Score: 0.000 | Cost: $1.145\nContinuing refinement... | Attempts: 15/50 | Best Score: 0.999 | Cost: $1.145\nRefining previous solutions... | Attempts: 15/50 | Best Score: 0.999 | Cost: $1.145\nTesting solutions... | Attempts: 15/50 | Best Score: 0.999 | Cost: $1.436\nFound potential solution, validating... | Attempts: 15/50 | Best Score: 1.000 | Cost: $1.436\nSolution found! | Attempts: 20/50 | Best Score: 1.000 | Cost: $1.436\nSolution found! üéâ | Attempts: 20/50 | Best Score: 1.000 | Cost: $1.436\n\n\nNice, let‚Äôs have a look at the test prediction\n\nexecutor = SandboxedExecutor()\ntest_pred = executor.run(solutions[0].solution, task, split='test')\nArcPair(test_pred.in_preds[0], test_pred.out_preds[0]).plot()\n\n\n\n\n\n\n\n\nAnd let‚Äôs inspect the description that led to a successful solution:\n\nprint(solutions[0].description.d)\n\n\nThe input grids contain scattered colored pixels where red and blue pixels serve as attraction points for other colors. Green pixels are attracted to and move adjacent to red pixels, while orange pixels are attracted to and move adjacent to blue pixels. The positions of red and blue pixels remain fixed, while green and orange pixels move to become orthogonally adjacent to their respective attractors, forming clusters in the output grid. The background black color and grid dimensions remain unchanged throughout the transformation.\n\nPretty good!",
    "crumbs": [
      "solve"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "arcsolver",
    "section": "",
    "text": "This library contains tools for visualizing, analyzing and solving tasks from the Abstraction and Reasoning Corpus (ARC) challenge dataset.\nAs this library was built using nbdev, the source code can be found in the jupyter notebooks directory (nbs).\nFull documentation available at https://agemoai.github.io/arcsolver.",
    "crumbs": [
      "arcsolver"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "arcsolver",
    "section": "Installation",
    "text": "Installation\n\nInstall claudette from its GitHub repository (PyPi version is a bit behind):\n\n$ pip install git+https://github.com/AnswerDotAI/claudette.git@5ea3a59\n\nInstall arcsolver:\n\n$ pip install arcsolver\n\n\n\n\n\n\nNote\n\n\n\nTo use the automated description or solution generation features of this library, access to Anthropic‚Äôs Claude Sonnet 3.5 model is required. Set the ANTHROPIC_API_KEY environment variable or configure appropriate credentials for AWS bedrock or Google Vertex.",
    "crumbs": [
      "arcsolver"
    ]
  },
  {
    "objectID": "index.html#key-features",
    "href": "index.html#key-features",
    "title": "arcsolver",
    "section": "Key Features",
    "text": "Key Features\n\nTask Management: Load and visualize ARC tasks with the ArcTask class\nObject-Centric Modelling: A set of primitive classes for representing grid objects and transformations\nLLM Integration: Designed to use Claude Sonnet 3.5 for automated task analysis and solution generation\nExtensible Architecture: Easy to add new primitives and helper functions to enhance solving capabilities",
    "crumbs": [
      "arcsolver"
    ]
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "arcsolver",
    "section": "Quick Start",
    "text": "Quick Start\n\nTask Representation\nThe task module provides classes for working with ARC tasks\n\nfrom arcsolver.task import ArcGrid, ArcPair, ArcTask\n\ntask = ArcTask('1e0a9b12'); task.plot()\n\n\n\n\n\n\n\n\nAn ArcTask comprises a list of input-output example ArcPairs, each of which holds two ArcGrids. Each class has convenient plot methods for visualization or directly outputting to binary strings that can be passed to Claude.\n\nprint(f\"Input grid 1 plot: {task.train[0].input.plot(to_base64=True)[:20]}...\")\n\nInput grid 1 plot: b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01H'...\n\n\n\n\nObject-centric Models\nThe ocm module provides a set of primitive classes for constructing object-centric models of ARC grids. For example:\n\nfrom arcsolver.ocm import Vector, Rectangle, Line, Grid, Color, Direction\n\ngrid = Grid(\n    size=Vector(8,8),\n    background_color=Color('grey'),\n    objects=[\n        Rectangle(position=Vector(1,1), size=Vector(2,2), color=Color('red')),\n        Line(position=Vector(6,1), direction=Direction.NE, length=6, color=Color('pink'))\n    ]\n)\nArcGrid(grid.to_array()).plot()\n\n\n\n\n\n\n\n\n\n\nTask Descriptions\nUse Claude to analyze and describe ARC tasks\n\nfrom arcsolver.describe import DescriptionGenerator\n\ndescriber = DescriptionGenerator()\nd = await describer.describe_task(task, 1); print(d[0].d)\n\n\nThe input grids contain various colored squares arranged on a black background in different positions. In the transformation, all colored squares ‚Äúfall‚Äù vertically to the bottom row while maintaining their relative horizontal positions and original colors. The rest of the grid becomes filled with black squares, resulting in an output where all non-black squares are aligned in the bottom row, preserving their left-to-right ordering from the input grid.\n\n\n\n\n\n\n\nWarning\n\n\n\nDepending on the task and the description strategy used (see docs), DescriptionGenerator may decompose the task into multiple images, resulting in a token-intensive prompt (~$0.10 using Sonnet 3.5).\n\n\n\n\nSolution Generation\nUse Claude to construct a solution to an ARC task, automatically refining its attempts based on execution and prediction error feedback.\n\nfrom arcsolver.solve import ArcSolver\n\nsolver = ArcSolver()\nsolutions = await solver.solve(task)\n\n\nSolving task: 1e0a9b12\nGenerating descriptions... | Attempts: 0/30 | Best Score: 0.000 | Cost: $0.000\nStarting solution attempts... | Attempts: 0/30 | Best Score: 0.000 | Cost: $0.142\nGenerating initial solutions... | Attempts: 0/30 | Best Score: 0.000 | Cost: $0.142\nTesting solutions... | Attempts: 0/30 | Best Score: 0.000 | Cost: $0.231\nContinuing refinement... | Attempts: 2/30 | Best Score: 0.866 | Cost: $0.231\nRefining previous solutions... | Attempts: 2/30 | Best Score: 0.866 | Cost: $0.231\nTesting solutions... | Attempts: 2/30 | Best Score: 0.866 | Cost: $0.332\nContinuing refinement... | Attempts: 4/30 | Best Score: 0.904 | Cost: $0.332\nRefining previous solutions... | Attempts: 4/30 | Best Score: 0.904 | Cost: $0.332\nTesting solutions... | Attempts: 4/30 | Best Score: 0.904 | Cost: $0.424\nContinuing refinement... | Attempts: 6/30 | Best Score: 0.951 | Cost: $0.424\nRefining previous solutions... | Attempts: 6/30 | Best Score: 0.951 | Cost: $0.424\nTesting solutions... | Attempts: 6/30 | Best Score: 0.951 | Cost: $0.528\nContinuing refinement... | Attempts: 8/30 | Best Score: 0.951 | Cost: $0.528\nRefining previous solutions... | Attempts: 8/30 | Best Score: 0.951 | Cost: $0.528\nTesting solutions... | Attempts: 8/30 | Best Score: 0.951 | Cost: $0.633\nContinuing refinement... | Attempts: 10/30 | Best Score: 0.958 | Cost: $0.633\nRefining previous solutions... | Attempts: 10/30 | Best Score: 0.958 | Cost: $0.633\nTesting solutions... | Attempts: 10/30 | Best Score: 0.958 | Cost: $0.732\nContinuing refinement... | Attempts: 12/30 | Best Score: 0.965 | Cost: $0.732\nRefining previous solutions... | Attempts: 12/30 | Best Score: 0.965 | Cost: $0.732\nTesting solutions... | Attempts: 12/30 | Best Score: 0.965 | Cost: $0.835\nFound potential solution, validating... | Attempts: 12/30 | Best Score: 1.000 | Cost: $0.835\nSolution found! | Attempts: 14/30 | Best Score: 1.000 | Cost: $0.835\nSolution found! üéâ | Attempts: 14/30 | Best Score: 1.000 | Cost: $0.835",
    "crumbs": [
      "arcsolver"
    ]
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "arcsolver",
    "section": "Contributing",
    "text": "Contributing\nContributions are welcome! Refined prompts, new OCM primitives, expanded tool-use, alternative retry strategy‚Ä¶\nFeel free to raise an issue or submit a PR.\n\nLearn More\nTo read about the motivation for building this tool, check out our blog and watch out for future posts",
    "crumbs": [
      "arcsolver"
    ]
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "examples",
    "section": "",
    "text": "In order to encourage Claude to respond with solutions in the correct style, it is helpful to provide a few examples and insert them in the conversation history\nsource",
    "crumbs": [
      "examples"
    ]
  },
  {
    "objectID": "examples.html#c7c7b",
    "href": "examples.html#c7c7b",
    "title": "examples",
    "section": "017c7c7b",
    "text": "017c7c7b\n\ntask = ArcTask('017c7c7b'); task.plot()\n\n\n\n\n\n\n\n\n\n\nExported source\nexample_017c7c7b = Example(\n    description=\"\"\"\\\nThe input grid is a 6x3 grid with a blue colored pattern on a black background. \\\nThe output grid is a 9x3 grid. The first 6 rows of the output grid contain the same pattern as the input grid \\\nand the additional rows are filled appropriately to form a cyclical or repeating pattern of rows. \\\nThe resulting cyclical patterns in the output grids have varying cycle lengths. \\\nThe color of the entire pattern in the output grid is changed from blue to red. \n\"\"\",\n    reasoning=\"\"\"\\\n1. Pattern & Transformation Analysis:\n   - Fixed-size grids: 6x3 input, 9x3 output\n   - Single blue pattern on black background transforms to red\n   - Pattern extends vertically with cyclic repetition\n   - Cycle length varies between examples\n   - Two key transformations: cyclic extension and color change (blue ‚Üí red)\n\n2. Shape Extraction & Representation:\n   - Entire grid is one cohesive pattern\n   - No need for complex shape extraction\n   - Simple Bitmap representation sufficient\n   - Background color consistent (black)\n\n3. Required Capabilities:\n   - Period detection for cyclic patterns\n   - Pattern extension while preserving structure\n   - Color transformation (value mapping 1 ‚Üí 2)\n   - No existing primitive handles cyclic patterns\n\n4. Implementation Strategy:\n   - Input: Single Bitmap object preserving full grid\n   - Output: Detect period, extend pattern, transform color\n   - New CyclicPattern primitive needed for:\n     * Period detection along specified axis\n     * Pattern extension to desired length\n     * Integration with existing primitives\n\n5. Edge Cases:\n   - Various cycle lengths (1, 2, 3...)\n   - Patterns without obvious repetition\n   - Full-length cycles\n\nThis suggests a solution focusing on pattern-level operations rather than individual shapes, \\\nwith a new CyclicPattern primitive handling the cyclic nature of the transformations. \\\nThe implementation can be straightforward since we're treating each grid as a single pattern, \\\nwith complexity mainly in period detection and extension.\n\"\"\",\n    new_primitives='''\\\nclass CyclicPattern(BaseModel):\n    \"\"\"\n    Identify, represent, and manipulate cyclic patterns in ARC task grids,\n    particularly for tasks involving pattern repetition and extension.\n    \"\"\"\n    data: np.ndarray\n    period: int\n    axis: int = Field(0, ge=0, le=1)\n\n    model_config = {\"arbitrary_types_allowed\": True}\n\n    @classmesthod\n    def from_array(cls, arr: np.ndarray, axis: int = 0) -&gt; 'CyclicPattern':\n        \"\"\"Create a CyclicPattern instance from a numpy array.\"\"\"\n        return cls(data=arr, period=cls.find_period(arr, axis), axis=axis)\n\n    @staticmethod\n    def find_period(arr: np.ndarray, axis: int = 0) -&gt; int:\n        \"\"\"Find the smallest period along a specified axis of a NumPy array.\"\"\"\n        n = arr.shape[axis]\n        if n == 0: return 0  # Undefined period for empty axis\n\n        for p in range(1, n):\n            pattern = np.take(arr, indices=range(p), axis=axis)\n            repeats = int(np.ceil(n / p))\n            tiled = np.concatenate([pattern] * repeats, axis=axis)\n            slicer = [slice(None)] * arr.ndim\n            slicer[axis] = slice(0, n)\n            tiled = tiled[tuple(slicer)]\n\n            if np.array_equal(arr, tiled): return p\n\n        return n  # The entire axis if no smaller period is found\n\n    def extend(self, length: int) -&gt; np.ndarray:\n        \"\"\"Extend the pattern to a specified length.\"\"\"\n        pattern = np.take(self.data, range(self.period), axis=self.axis)\n        repeats = [1] * self.data.ndim\n        repeats[self.axis] = length // self.period + 1\n        tiled = np.tile(pattern, repeats)\n        slices = [slice(None)] * self.data.ndim\n        slices[self.axis] = slice(length)\n        return tiled[tuple(slices)]\n\n    def to_array(self) -&gt; np.ndarray:\n        \"\"\"Convert the cyclic pattern to a numpy array.\"\"\"\n        return self.data\n\n    def __len__(self) -&gt; int:\n        \"\"\"Get the length of the pattern along its axis.\"\"\"\n        return self.data.shape[self.axis]\\\n''',\n    input_model='''\\\nclass InputModel(Grid):\n    size: Literal[Vector(6, 3)]\n\n    @classmethod\n    def from_array(cls, arr: np.ndarray) -&gt; 'InputModel':\n        return cls(\n            size=Vector(*arr.shape),\n            objects=[Bitmap(position=Vector(0, 0), data=arr)]\n            )\\\n''',\n    output_model='''\\\nclass OutputModel(Grid):\n    size: Literal[Vector(9, 3)]\n\n    @classmethod\n    def from_input(cls, input_grid: InputModel) -&gt; 'OutputModel':\n        input_pattern = CyclicPattern.from_array(input_grid.objects[0].data, axis=0)\n        extended_pattern = input_pattern.extend(9)\n        red_pattern = np.where(extended_pattern == 1, 2, 0)\n        \n        return cls(\n            size=Vector(9,3),\n            objects=[Bitmap(position=Vector(0, 0), data=red_pattern)]\n        )\\\n'''\n)",
    "crumbs": [
      "examples"
    ]
  },
  {
    "objectID": "examples.html#d67576",
    "href": "examples.html#d67576",
    "title": "examples",
    "section": "36d67576",
    "text": "36d67576\n\ntask = ArcTask('36d67576'); task.plot()\n\n\n\n\n\n\n\n\n\n\nExported source\nexample_36d67576 = Example(\n    description='''\\\nThe input grid contains multiple shapes: one complete shape and several partial copies of that shape. \\\nThe partial copies are transformed versions of the complete shape (rotated and/or reflected). \\\nThe task is to identify how each partial shape relates to the complete shape and replace each partial shape \\\nwith its complete transformed version.\\\n''',\n    reasoning='''\\\n1. Task Analysis:\n   - Input contains multiple shapes:\n     * One complete reference shape\n     * Multiple partial shapes\n   - Partial shapes are transformed versions of complete shape\n   - Transformations include rotations and reflections\n   - Goal: Replace partials with complete transformed versions\n\n2. Shape Identification Requirements:\n   - Need to extract contiguous shapes from grid\n   - Must distinguish complete from partial shapes\n   - First shape extracted is likely complete (largest)\n   - ShapeExtractor primitive suitable for this task\n\n3. Transformation Analysis:\n   - Need to test all possible transformations:\n     * Rotations (0¬∞, 90¬∞, 180¬∞, 270¬∞)\n     * Reflections (horizontal, vertical)\n     * Transpositions\n   - Must match partial shapes allowing for missing parts\n   - PatternMatcher with 'allow_extra' mode ideal for this\n\n4. Implementation Strategy:\n   - Input Model:\n     * Separate complete shape from partials\n     * Store as Bitmap objects\n     * Use background_color for grid reconstruction\n   - Output Model:\n     * Generate all possible transformations\n     * Find best match for each partial shape\n     * Replace partials with complete transformed versions\n   \n5. Edge Cases:\n   - Multiple equally-sized shapes\n   - Partial shapes with minimal overlap\n   - Ambiguous transformations\n   - Different colored shapes\n\nNo new primitives needed as existing ones (ShapeExtractor, PatternMatcher, Bitmap) \nprovide all required functionality for shape extraction, transformation matching, \nand grid reconstruction.\\\n''',\n    new_primitives='',\n    input_model='''\\\nclass InputModel(Grid):\n    background_color: Literal[Color(0)] = Color(0)\n    full_shape: Bitmap\n    partial_shapes: List[Bitmap]\n\n    @model_validator(mode='before')\n    def set_objects(cls, values):\n        values['objects'] = [values['full_shape']] + values['partial_shapes']\n        return values\n\n    @classmethod\n    def from_array(cls, arr: np.ndarray) -&gt; 'InputModel':\n        arr_mask = (arr != 0).astype(int)\n        shape_info = ShapeExtractor.extract_contiguous_regions(arr_mask, 1)\n        colored_shapes = []\n        for shape, pos in shape_info:\n            colored_shapes.append((\n                arr[pos[0]:pos[0]+shape.shape[0], pos[1]:pos[1]+shape.shape[1]],\n                pos\n                ))\n        \n        full_shape = Bitmap(position=Vector(*colored_shapes[0][1]),\n                          data=colored_shapes[0][0])\n        partial_shapes = [\n            Bitmap(position=Vector(*pos), data=shape) for shape, pos in colored_shapes[1:]\n        ]\n\n        return cls(\n            size=Vector(*arr.shape),\n            full_shape=full_shape,\n            partial_shapes=partial_shapes\n        )\\\n''',\n    output_model='''\\\nclass OutputModel(Grid):\n    @classmethod\n    def from_input(cls, input_grid: InputModel) -&gt; 'OutputModel':\n        full_shape = input_grid.full_shape.to_array()\n        transformations = [\n            full_shape,\n            np.rot90(full_shape, 1),\n            np.rot90(full_shape, 2),\n            np.rot90(full_shape, 3),\n            np.flip(full_shape, 0),\n            np.flip(full_shape, 1),\n            full_shape.T,\n            np.fliplr(full_shape).T\n        ]\n        \n        new_shapes = []\n        for obj in input_grid.partial_shapes:\n            # Create a grid with just the partial shape object\n            obj_arr = obj.to_array(input_grid.size)\n            obj_arr[obj_arr == -1] = 0\n            # Find the transformation that best matches the partial shape\n            matches = [(t, *PatternMatcher.find_best_match(obj_arr, t, match_type='allow_extra')) for t in transformations]\n            best_match = max(matches, key=lambda m: m[-1])  # matches is a list of (transformation, position, overlap_count)\n            new_shapes.append(Bitmap(position=best_match[1], data=best_match[0]))\n        \n        return cls(\n            size=input_grid.size,\n            background_color=input_grid.background_color,\n            objects=[input_grid.full_shape] + new_shapes\n        )\\\n'''\n)",
    "crumbs": [
      "examples"
    ]
  },
  {
    "objectID": "examples.html#bbfb7",
    "href": "examples.html#bbfb7",
    "title": "examples",
    "section": "007bbfb7",
    "text": "007bbfb7\n\ntask = ArcTask('007bbfb7'); task.plot()\n\n\n\n\n\n\n\n\n\n\nExported source\nexample_007bbfb7 = Example(\n    description='''\\\nThe input grid is a 3x3 grid with a single-colored pattern on a black background. \\\nThe output grid size is 9x9. Each pixel in the input grid corresponds to a 3x3 section in the output grid. \\\nFor each pixel in the input grid that is colored, its corresponding section of the output grid is filled \\\nwith a copy of the entire input grid.\\\n''',\n    reasoning='''\\\n1. Pattern Analysis:\n   - Input: 3x3 grid with single-colored pattern on black\n   - Output: 9x9 grid with recursive pattern structure\n   - Each colored pixel in input maps to 3x3 section in output\n   - These 3x3 sections contain copies of entire input pattern\n\n2. Transformation Properties:\n   - Scale factor is 3 (3x3 ‚Üí 9x9)\n   - Pattern replication follows a specific rule:\n     * For each non-zero input pixel\n     * Replace with full input pattern\n     * For zero pixels, keep as zero\n   - This resembles a Kronecker product operation:\n     * Binary mask of pattern √ó Original pattern\n     * Will naturally create the required structure\n\n3. Implementation Strategy:\n   - Input Model:\n     * Single Bitmap sufficient for 3x3 pattern\n     * Fixed size constraint (3x3)\n   - Output Model:\n     * Create binary mask of non-zero elements\n     * Apply Kronecker product for pattern replication\n     * Result gives correct 9x9 structure\n\n4. Edge Cases:\n   - Empty input patterns\n   - Single pixel patterns\n   - Fully filled patterns\n   - Different colors\n\nNo new primitives needed as the transformation can be handled efficiently using \nnumpy's Kronecker product (kron) operation combined with existing Bitmap primitive.\\\n''',\n    new_primitives='',\n    input_model='''\\\nclass InputModel(Grid):\n    size: Literal[Vector(3, 3)]\n    pattern: Bitmap\n\n    @model_validator(mode='before')\n    def set_objects(cls, values):\n        values['objects'] = [values['pattern']]\n        return values\n\n    @classmethod\n    def from_array(cls, arr: np.ndarray) -&gt; 'InputModel':\n        return cls(\n            size=Vector(*arr.shape),\n            pattern=Bitmap(position=Vector(i=0, j=0), data=arr)\n        )\\\n''',\n    output_model='''\\\nclass OutputModel(Grid):\n    size: Literal[Vector(9, 9)] = Vector(9, 9)\n\n    @classmethod\n    def from_input(cls, input_grid: InputModel) -&gt; 'OutputModel':\n        input_pattern = input_grid.pattern.data\n        binary_mask = (input_pattern != 0).astype(int)\n        output_pattern = np.kron(binary_mask, input_pattern)\n        \n        return cls(\n            objects=[Bitmap(position=Vector(0, 0), data=output_pattern)]\n        )\\\n'''\n)\n\n\n\n\nExported source\nexamples = [example_017c7c7b, example_36d67576, example_007bbfb7]",
    "crumbs": [
      "examples"
    ]
  },
  {
    "objectID": "task.html",
    "href": "task.html",
    "title": "task",
    "section": "",
    "text": "source\n\nArcGrid\n\n ArcGrid (data:numpy.ndarray)\n\nA single ARC grid\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nndarray\n2d array of integers (0‚Äì9)\n\n\n\nEach ARC task is made up of pairs of input and output ‚Äúgrids‚Äù, which are 2-d arrays/matrices of integers\nThis class stores a single ARC grid as a numpy array. We can then easily visualise the grid using the plot() method\n\nin_arr = np.random.randint(0,9, (4,4))\nin_grid = ArcGrid(in_arr); in_grid\n\nGrid(shape=(4, 4))\n\n\n\nin_grid.plot()\n\n\n\n\n\n\n\n\nThe plot method also supports returning the base64-encoded string of the image directly\n\nprint(f\"Base64 string: '{in_grid.plot(to_base64=True)[:20]}...'\")\n\nBase64 string: 'b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01H'...'\n\n\nArcGrids support equality checks, making it easy to test predicted grids\n\nassert in_grid != ArcGrid(np.ones((3,3), dtype=int))\nassert in_grid == ArcGrid(in_arr)\n\n\nsource\n\n\nArcPair\n\n ArcPair (input_grid:__main__.ArcGrid|numpy.ndarray,\n          output_grid:__main__.ArcGrid|numpy.ndarray)\n\nA pair of ARC grids, typically [input, output]. Can also be used for [output, prediction]\n\n\n\n\nType\nDetails\n\n\n\n\ninput_grid\nmain.ArcGrid | numpy.ndarray\nInput grid\n\n\noutput_grid\nmain.ArcGrid | numpy.ndarray\nOutput grid\n\n\n\n\nout_arr = np.random.randint(0, 9, (16,16))\npair = ArcPair(in_grid, ArcGrid(out_arr))\npair.plot()\n\n\n\n\n\n\n\n\nThe output grids in ARC tasks are often a different size to the input grids. When plotting pairs of grids, we can specify whether we want the grids to be on the same scale (i.e.¬†one cell is equal size in both plots) or whether to rescale each grid to fill its half of the plot.\n\npair.plot(same_scale=False)\n\n\n\n\n\n\n\n\n\nsource\n\n\nArcTask\n\n ArcTask (task_id:str, split:str='train',\n          data_dir:str|pathlib.Path|None=None)\n\nAn ARC task\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntask_id\nstr\n\n8-digit task id\n\n\nsplit\nstr\ntrain\nARC public dataset split (‚Äòtrain‚Äô or ‚Äòeval‚Äô)\n\n\ndata_dir\nstr | pathlib.Path | None\nNone\nPath to ARC data directory (defaults to '/path/to/arcsolver/arc_data/data')\n\n\n\n\nt = [f.split('.')[0] for f in os.listdir('../arcsolver/arc_data/data/training')][1]\ntask = ArcTask(t); task\n\nArcTask(id='c8cbb738', train_examples=3, test_examples=1)\n\n\nAn ArcTask stores the training and test examples, each as a list of ArcPair objects.\n\ntask.train\n\n[ArcPair(input_shape=(12, 11), output_shape=(5, 5)),\n ArcPair(input_shape=(10, 8), output_shape=(3, 3)),\n ArcPair(input_shape=(12, 14), output_shape=(5, 5))]\n\n\n\ntask.plot()\n\n\n\n\n\n\n\n\nAgain, we can choose whether to rescale the plots\n\ntask.plot(same_scale=False)\n\n\n\n\n\n\n\n\n\nsource\n\n\nget_task_files\n\n get_task_files (split:str)\n\nGet list of files from either training or evaluation data.\n\n\n\n\nType\nDetails\n\n\n\n\nsplit\nstr\n‚Äòtrain‚Äô or ‚Äòeval‚Äô\n\n\nReturns\nlist",
    "crumbs": [
      "task"
    ]
  },
  {
    "objectID": "describe.html",
    "href": "describe.html",
    "title": "describe",
    "section": "",
    "text": "This module implements two different strategies for getting Claude to generate a description of a given ARC task.\nsource",
    "crumbs": [
      "describe"
    ]
  },
  {
    "objectID": "describe.html#approach-1-direct-description",
    "href": "describe.html#approach-1-direct-description",
    "title": "describe",
    "section": "Approach 1: Direct description",
    "text": "Approach 1: Direct description\nThe most straightforward approach is to simply provide an image of all examples in a task and ask for a solution description.\nWe use a system prompt that explains the objective in detail and instructs the model to perform chain of thought reasoning before formulating the final description.\n\nsource\n\nDescriptionGenerator.describe_direct\n\n DescriptionGenerator.describe_direct (task:arcsolver.task.ArcTask|str,\n                                       n:int=1, temp:float=0.5,\n                                       prefill:str='&lt;reasoning&gt;',\n                                       **kwargs)\n\nGenerate n direct descriptions of the task concurrently.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntask\narcsolver.task.ArcTask | str\n\nARC task or task ID to describe\n\n\nn\nint\n1\nNo.¬†of descriptions to generate\n\n\ntemp\nfloat\n0.5\nTemperature for generation (higher for diversity)\n\n\nprefill\nstr\n\nText to prefill the assistant‚Äôs response with\n\n\nkwargs\n\n\n\n\n\nReturns\nList\n\nList of Description objects\n\n\n\nLet‚Äôs demonstrate with an example task:\n\n\nTask: f25fbde4\n\n\n\n\n\n\n\n\n\n\n\ndescriber = DescriptionGenerator(model, 'bedrock')\nd_direct = await describer.describe_direct(task)\nprint(d_direct[0].d)\n\n\nThe input grids contain a pattern of yellow cells on a black background forming a continuous path or shape. The output grid is determined by finding the rectangular region defined by the extremal yellow cells in the input (leftmost, rightmost, topmost, and bottommost). In the output, all cells within this rectangular boundary are filled with yellow, while maintaining black cells outside this region, effectively creating a solid yellow shape that encompasses the original pattern‚Äôs extent.\n\nThis description is nearly right. The wording is strange but it seems to have correctly identified that the output is the minimal bounding box around the yellow shape. However, it has not spotted that the yellow shape has been scaled up in size.\nThis is a common failure mode for Claude. It often erroneously declares that two similar shapes are identical. It can often form a rough idea of what is happening in a task but when faced with multiple similar objects within grids, it fails to identify and distinguish specific shapes. This motivates trying an alternative approach.",
    "crumbs": [
      "describe"
    ]
  },
  {
    "objectID": "describe.html#approach-2-indirect-description",
    "href": "describe.html#approach-2-indirect-description",
    "title": "describe",
    "section": "Approach 2: Indirect Description",
    "text": "Approach 2: Indirect Description\nInstead of presenting the entire task‚Äîwhich can sometimes feature 5+ pairs of grids‚Äîall at once to Claude, we can instead generate independent descriptions based on individual pairs of grids and subsequently ask Claude to synthesize the information contained in the set of descriptions to form a final unified description.\nPros:\n\nLarger grids within the image and less whitespace\nClaude can pick out finer details from within the grids\nCan generate highly descriptive summaries of each pair\n\nCons:\n\nMany task solutions can not be identified or determined from an isolated example pair\nMore token-intensive (expensive)\n\n\nsource\n\nDescriptionGenerator.describe_indirect\n\n DescriptionGenerator.describe_indirect (task:arcsolver.task.ArcTask|str,\n                                         n:int=1, temp:float=0.6,\n                                         tools:Optional[list]=None,\n                                         **kwargs)\n\nGenerate n direct descriptions of the task concurrently.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntask\narcsolver.task.ArcTask | str\n\nARC task or task ID to describe\n\n\nn\nint\n1\nNo.¬†of descriptions to generate\n\n\ntemp\nfloat\n0.6\nTemperature for generation (higher for diversity)\n\n\ntools\nOptional\nNone\nList of tools to make available to Claude (defaults to [ShapeExtractor.extract_shapes])\n\n\nkwargs\n\n\n\n\n\nReturns\nList\n\nList of Description objects\n\n\n\nFor this approach, we have also implemented tool-use. In order to help Claude accurately identify shapes, we provide a ShapeExtractor function that can be used\n\nsource\n\n\nShapeExtractor.extract_shapes\n\n ShapeExtractor.extract_shapes (grid_idx:int, color:str,\n                                include_diagonal:bool)\n\nExtract contiguous regions of a specified color from a grid.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ngrid_idx\nint\nIndex of the target grid\n\n\ncolor\nstr\nColor of shapes to extract\n\n\ninclude_diagonal\nbool\nConsider diagonally adjacent cells as connected?\n\n\nReturns\nlist\nList of extracted shapes (boolean arrays) and their positions\n\n\n\nIn our system prompt, we instruct Claude to generate an intial hypothesis about the task solution, and then use the shape extractor tool to inspect shapes as neccessary to inform its final judgement. Claude can choose how many times to call the function and which colored shapes to extract from which grids. Once it has enough information to form a final description, the conversation ends.\n\nd_indirect = await describer.describe_indirect(task)\nprint(d_indirect[0].d)\n\n\nThe input grid is a 9x9 black grid containing yellow pixels arranged in various patterns. The transformation converts each yellow pixel in the input into a 2x2 block of yellow pixels in the output, while maintaining the relative spatial relationships between yellow elements. The output grid dimensions are reduced to accommodate the transformed pattern while preserving the black background. This transformation creates a blocky, enlarged version of the original pattern in a smaller grid, with the final dimensions adjusted to fit the transformed elements efficiently.\n\nUsing this method, it has generated a much more accurate description of the task. We can inspect the chat history to see its use of the tool:\n\nprint(d_indirect[0].chats[1].h[1]['content'][0].text)\n\n&lt;initial_analysis&gt;\nBased on visual inspection:\n- Input grid shows a sparse diagonal-like pattern of yellow pixels on black background\n- Output grid appears to show a more concentrated arrangement of yellow pixels\n- The output grid is smaller (6x6 vs 9x9)\n- Initial hypothesis: The yellow pixels might be getting \"compressed\" into a smaller space while maintaining some kind of pattern\n- Key uncertainty: Whether the yellow pixels form a specific connected shape that's being transformed\n- Tool analysis would be helpful to:\n  * Verify if the yellow pixels form a connected shape in either grid\n  * Count exact number of yellow pixels to see if they're preserved\n&lt;/initial_analysis&gt;\n\nLet me extract the yellow shapes from both grids:\n\n\n\nd_indirect[0].chats[1].h[1]['content'][1]\n\nToolUseBlock(id='toolu_bdrk_01UsGpZS8zyEW238PbE3tZDg', input={'grid_idx': 2, 'color': 'yellow', 'include_diagonal': True}, name='extract_shapes', type='tool_use')\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that the indirect method is significantly more expensive than the direct method. It creates separate chat instances for each pair of grids, including an image and triggering a multi-turn tool-calling conversation.\n\n\n\nprint(f\"Direct cost: ${d_direct[0].cost:.3f}\")\nprint(f\"Indirect cost: ${d_indirect[0].cost:.3f}\")\n\nDirect cost: $0.012\nIndirect cost: $0.101\n\n\n\nsource\n\n\nDescriptionGenerator.describe_task\n\n DescriptionGenerator.describe_task (task:arcsolver.task.ArcTask|str,\n                                     n_direct:int=1, n_indirect:int=1,\n                                     temp:float=0.7, **kwargs)\n\nGenerate multiple descriptions of a task using one or both strategies concurrently.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntask\narcsolver.task.ArcTask | str\n\nARC task or task ID to describe\n\n\nn_direct\nint\n1\nNo.¬†of direct descriptions to generate\n\n\nn_indirect\nint\n1\nNo.¬†of indirect descriptions to generate\n\n\ntemp\nfloat\n0.7\nTemperature for generation (higher for diversity)\n\n\nkwargs\n\n\n\n\n\nReturns\nList\n\nList of Description objects\n\n\n\nThis method allows us to generate descriptions using either or both strategies at the same time.",
    "crumbs": [
      "describe"
    ]
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "utils",
    "section": "",
    "text": "source\n\nparse_from_xml\n\n parse_from_xml (input_text:str, tag_name:str)\n\n*Parse content from an XML-like string for a specific tag.\nArgs: input_text (str): The input text containing XML-like tags. tag_name (str): The name of the tag to parse.\nReturns: str: The content within the specified tag.\nRaises: TagNotFoundError: If the specified tag is not found in the text. MultipleTagsError: If multiple instances of the tag are found. NoContentError: If the tag is present but contains no content.*",
    "crumbs": [
      "utils"
    ]
  }
]